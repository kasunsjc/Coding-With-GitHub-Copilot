# Demo 5: Team Adoption — AI Without Compromising Standards

> **Duration:** ~8 minutes  
> **Goal:** Show how teams can adopt Copilot for Bicep/IaC while maintaining security and quality

---

## What You'll Demonstrate

1. **Custom instructions** — `.github/copilot-instructions.md` for Bicep standards
2. **PR review templates** — IaC-specific review checklists
3. **Security anti-patterns** — What Copilot might generate (and how guardrails catch it)
4. **Bicep linter config** — `bicepconfig.json` as automated quality enforcement
5. **Team adoption policy** — Practical rollout guidance

---

## Live Demo Steps

### Step 1: Custom Copilot Instructions (2 min)

Open `.github/copilot-instructions.md` and explain:

> "This file teaches Copilot YOUR team's standards. Every suggestion it makes
> in this repo will follow these rules — naming conventions, security requirements,
> tagging policies, even module structure."

**Key points:**
- Lives in the repo — version controlled
- Team agrees on standards ONCE, Copilot follows them everywhere
- New team members get the same quality from Copilot on day one

### Step 2: PR Review Template (1 min)

Open `.github/pull_request_template.md` and show:

> "Even with Copilot helping, every PR goes through human review.
> This checklist ensures IaC-specific items are always verified."

### Step 3: Security Awareness (3 min)

Open `examples/security-awareness.bicep`. For each anti-pattern:

1. Show the **insecure** version — "Copilot might suggest this without context"
2. Show the **secure** version — "With proper instructions, it generates this instead"
3. Explain the **guardrail** — linter rule, OIDC policy, or review checklist item

**Anti-patterns covered:**
- Hardcoded secrets in parameters
- Public blob access enabled
- Missing TLS enforcement
- Overly permissive network rules
- Missing managed identity

### Step 4: Bicep Linter Configuration (1 min)

Open `examples/bicepconfig.json` and show:

> "This catches mistakes BEFORE code review — whether written by a human
> or generated by Copilot. It's your automated safety net."

### Step 5: Adoption Policy (1 min)

Briefly reference `examples/team-adoption-policy.md`:

> "Start small — pick a low-risk module, measure the results,
> then expand. This policy template gives your team a structure."

---

## Talking Points

- "Copilot is a tool, not a replacement for engineering judgment"
- "The best teams don't restrict AI — they create guardrails that make it safe"
- "Custom instructions are the secret weapon — they're like onboarding Copilot to your team"
- "Linter + PR template + custom instructions = defense in depth"
- "Measure before and after: deployment time, PR cycle time, defect rate"

---

## Key Takeaway

```
┌─────────────────────────────────────────────────────┐
│                  DEFENSE IN DEPTH                    │
│                                                      │
│   Layer 1: copilot-instructions.md                   │
│            → Guides Copilot at generation time        │
│                                                      │
│   Layer 2: bicepconfig.json (Linter)                 │
│            → Catches issues at edit time              │
│                                                      │
│   Layer 3: az bicep build / what-if                  │
│            → Validates at build time                  │
│                                                      │
│   Layer 4: PR Template + Human Review                │
│            → Catches nuance at review time            │
│                                                      │
│   Layer 5: Azure Policy                              │
│            → Enforces compliance at deploy time       │
└─────────────────────────────────────────────────────┘
```
